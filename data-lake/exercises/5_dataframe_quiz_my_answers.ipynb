{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with DataFrames Coding Quiz\n",
    "\n",
    "Use this Jupyter notebook to find the answers to the quiz in the previous section. There is an answer key in the next part of the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import desc\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "# 2) instantiate a Spark session \n",
    "spark = SparkSession.builder.appName('Data Wrangling').getOrCreate()\n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)\n",
    "# 4) write code to answer the quiz questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.select('page').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\" (empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "# list all pages\n",
    "pages = user_log.select('page').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(page='Submit Downgrade'),\n",
       " Row(page='Downgrade'),\n",
       " Row(page='Logout'),\n",
       " Row(page='Save Settings'),\n",
       " Row(page='Settings'),\n",
       " Row(page='NextSong'),\n",
       " Row(page='Upgrade'),\n",
       " Row(page='Error'),\n",
       " Row(page='Submit Upgrade')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "# list of pages that empty user visited\n",
    "empty_user_pages_as_list = user_log.select('page').where(user_log.userId == '').dropDuplicates().rdd.flatMap(lambda i:i).collect()\n",
    "\n",
    "# filter pages that empty user did not visit\n",
    "not_visit_page = pages.filter(~pages['page'].isin(empty_user_pages_as_list))\n",
    "not_visit_page.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "What type of user does the empty string user id most likely refer to?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use this space to explore the behavior of the user with an empty string\n",
    "# empty user is either a guest or a logged out user\n",
    "#user_log.filter(user_log.userId=='').count()\n",
    "#user_log.filter(((user_log.auth == 'Logged Out')|(user_log.auth == 'Guest')) & (user_log.userId == '')).count()\n",
    "user_log.filter(((user_log.auth == 'Logged Out') | (user_log.auth == 'Guest')) & (user_log.userId != '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "#user_log.printSchema()\n",
    "user_log.select('userId','gender').dropDuplicates().where(user_log.gender == 'F').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Coldplay', count=83)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "#get most played actists\n",
    "#user_log.printSchema()\n",
    "user_log.select('userId','song','artist').filter(user_log.artist !=\"null\").groupby(user_log.artist).count().orderBy(desc('count')).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "#user_log.select('userId','page').take(20)\n",
    "#user_log.select('userId','page','ts').where(col('userId') == '1046').orderBy(col('ts')).take(15)\n",
    "# window with range and descending order: https://stackoverflow.com/questions/59571231/how-spark-rangebetween-works-with-descending-order\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.functions import count as Fcount\n",
    "from pyspark.sql.functions import avg as Favg\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "#user_log.select('page').dropDuplicates().show()\n",
    "#windowval = Window.partitionBy(\"userId\").orderBy(desc(\"ts\")).rangeBetween(Window.unboundedPreceding,Window.currentRow) #Window.currentRow=0\n",
    "#user_log.filter(col('userId') == '1046').withColumn(\"phase\", Fsum(\"userId\").over(windowval)).select('userId','phase','ts').take(1000)\n",
    "#mark homepage visit as one, others as 0\n",
    "udf_mark_homepage = udf(lambda x: 1 if x == 'Home' else 0, IntegerType())\n",
    "user_log_with_marked_homepage = user_log.withColumn('isHomepageVisit',udf_mark_homepage('page'))\n",
    "# phase 0:before first time visiting home, 1:when visiting home and before the 2nd visit to home, \n",
    "# 2: 2nd visit to home and after\n",
    "user_window_by_timestamp = Window.partitionBy('userId').orderBy(desc('ts')) \\\n",
    ".rangeBetween(Window.unboundedPreceding,Window.currentRow) \n",
    "user_with_phase = user_log_with_marked_homepage \\\n",
    ".withColumn(\"phase\",Fsum('isHomepageVisit').over(user_window_by_timestamp))\n",
    "#user_with_phase.filter(col('userId')=='2162').select('userId','page','phase').take(50)\n",
    "# get list of users who visit home the 2nd time\n",
    "return_to_homepage_user_list = user_with_phase.filter(col('phase')==2).select('userId').dropDuplicates().rdd.flatMap(lambda i:i).collect()\n",
    "# filter user that visited home the 2nd time, visited NextSong page between first and 2nd visit to Home,\n",
    "# then count these instances for each user, and average out\n",
    "user_with_phase \\\n",
    ".filter((col('userId').isin(return_to_homepage_user_list)) \\\n",
    "        & ((col('phase')==1) & (col('page')=='NextSong'))).groupBy('userId') \\\n",
    ".count() \\\n",
    ".select(Favg('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
